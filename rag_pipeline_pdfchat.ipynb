{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGdaB0Cxphe1"
      },
      "source": [
        "**Install Required Packages**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQlbUG13pftv"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install pdfminer.six\n",
        "!pip install streamlit\n",
        "!pip install pickle5\n",
        "!pip install langchain\n",
        "!pip install langchain-groq\n",
        "!pip install faiss-cpu\n",
        "!pip install huggingface_hub\n",
        "!pip install -U langchain-community\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCki3mjNpq-U"
      },
      "source": [
        "**Import Libraries and Initialization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "POT8K6EfpqyY"
      },
      "outputs": [],
      "source": [
        "from pdfminer.high_level import extract_text\n",
        "import os\n",
        "import pickle\n",
        "import time\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.chains import RetrievalQA\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ouqseKcpxvN"
      },
      "source": [
        "**Initialize LLM (Language Model)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aCW8WXkbp11r"
      },
      "outputs": [],
      "source": [
        "language_model = ChatGroq(temperature=0, \n",
        "                          groq_api_key=\"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\", \n",
        "                          model_name=\"llama-3.1-70b-versatile\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMcHPAu9p6A6"
      },
      "source": [
        "**File Upload**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U4RLG_vmp_dR"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded_docs = files.upload()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gb4JsJcYqDBd"
      },
      "source": [
        "**Extract and Split Text from Uploaded PDFs**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XBCx31MAqIRy"
      },
      "outputs": [],
      "source": [
        "def extract_and_split_text_from_docs():\n",
        "    entire_text = \"\"\n",
        "\n",
        "    # Extract text from all uploaded PDFs\n",
        "    for uploaded_doc in uploaded_docs.keys():\n",
        "        doc_text = extract_text(uploaded_doc)\n",
        "        entire_text += doc_text + \"\\n\"\n",
        "\n",
        "    # Split text into chunks\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
        "    text_chunks = text_splitter.split_text(entire_text)\n",
        "\n",
        "    return text_chunks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZQiL1AVqLUc"
      },
      "source": [
        "**Build FAISS Index from Text Chunks**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K1qOZ2CMqRYs"
      },
      "outputs": [],
      "source": [
        "def build_faiss_index_from_chunks(text_chunks):\n",
        "    # Create embeddings and vector store\n",
        "    embeddings_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "    faiss_vector_store = FAISS.from_texts(text_chunks, embeddings_model)\n",
        "\n",
        "    # Save FAISS index\n",
        "    print(\"Building FAISS index...\")\n",
        "    time.sleep(2)\n",
        "\n",
        "    # Save the FAISS index to a pickle file\n",
        "    index_file_path = 'faiss_store_groq.pkl'\n",
        "    with open(index_file_path, \"wb\") as f:\n",
        "        pickle.dump(faiss_vector_store, f)\n",
        "\n",
        "    print(\"Text extracted and FAISS index saved.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRuLB_FqqdnH"
      },
      "source": [
        "**Query Input and Retrieval**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJ2T_a2wqjeb"
      },
      "outputs": [],
      "source": [
        "user_query = input(\"Ask a Question: \")\n",
        "if user_query:\n",
        "    index_file_path = 'faiss_store_groq.pkl'\n",
        "    if os.path.exists(index_file_path):\n",
        "        with open(index_file_path, \"rb\") as f:\n",
        "            faiss_vector_store = pickle.load(f)\n",
        "            retrieval_chain = RetrievalQA.from_llm(llm=language_model, retriever=faiss_vector_store.as_retriever())\n",
        "\n",
        "        # Get response\n",
        "        query_result = retrieval_chain.run(user_query)\n",
        "\n",
        "        # Display answer\n",
        "        print(\"Answer:\")\n",
        "        print(query_result)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMqphYi0jtlVXuO9AxxvdqI",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
